# -*- coding: utf-8 -*-
"""job_analysis_sp_eda.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RM05buYvvcQlxZuV4tjmy4rWEDXXCNi9

##1. Library
"""

import pandas as pd
from sklearn.preprocessing import OrdinalEncoder, StandardScaler 



data = pd.read_csv('data cleaning/data for downstream/cdata_for_sp.csv', index_col= 0)

"""##data dimensions"""

print(f'There are {data.shape[0]} data points and {data.shape[1]} features in the dataset')


#data preprocessing
data_cat_ord_enc = data[['CompanySize','CompanyRevenue','JobSeniority']]

data_cat_one_hot = data[['CompanyType','CompanySector','JobType','OfficeCity','OfficeState']]

data_num = data[['AvgSalary','CompanyRating','CompanyAge', 'Python', 'Rstudio', 'DataVisualization','Tableau', 'PowerBI', 'Spark', 'aws', 'Azure']]


#OrdinalEncoding
data_cat_ord_enc['CompanySize'] = data_cat_ord_enc['CompanySize'].map(lambda x: x.strip())
data_cat_ord_enc['CompanyRevenue'] = data_cat_ord_enc['CompanyRevenue'].map(lambda x: x.strip())

companysize_encoder = OrdinalEncoder(categories = [["1 to 50 Employees", "51 to 200 Employees", "201 to 500 Employees", "501 to 1000 Employees","1001 to 5000 Employees","5001 to 10000 Employees",'10000+ Employees']])
data_cat_ord_enc['CompanySize'] = companysize_encoder.fit_transform(data_cat_ord_enc['CompanySize'].values.reshape(-1,1))

companyrevenue_encoder = OrdinalEncoder(categories = [["Less than $1 million (USD)", "$1 to $5 million (USD)", "$5 to $25 million (USD)", "$25 to $100 million (USD)","$100 to $500 million (USD)","$500 millionto $1 billion (USD)",'$1 to $5 billion (USD)','$5 to $10 billion (USD)','$10+ billion (USD)']])
data_cat_ord_enc['CompanyRevenue'] = companyrevenue_encoder.fit_transform(data_cat_ord_enc['CompanyRevenue'].values.reshape(-1,1))


jobseniority_encoder = OrdinalEncoder(categories = [['junior','senior']])
data_cat_ord_enc['JobSeniority'] = jobseniority_encoder.fit_transform(data_cat_ord_enc['JobSeniority'].values.reshape(-1,1))


#one hot encoding
data_dum = pd.get_dummies(data_cat_one_hot, drop_first= True)

data_final = pd.concat([data_num,data_cat_ord_enc,data_dum], axis = 1)

#feature scaling
col = data_final[['AvgSalary','CompanyRating','CompanyAge']]
data_final.drop(col, axis = 1, inplace = True)

standard_scale = StandardScaler()
col1 = standard_scale.fit_transform(col)
data_scaled = pd.DataFrame(col1, columns = col.columns)

data_scaled.head()

df_final = pd.concat([data_scaled, data_final], axis=1)

#model
df_final.to_csv('data cleaning/data for downstream/forautoml.csv',index=False)





















